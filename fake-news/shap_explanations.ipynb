{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fake news classification meets XAI\n\nThis notebook is based on previous work during [EDA](https://www.kaggle.com/code/adrianabukaa/fake-news-eda) and it is dedicated to veryfying some hypothesis about potential one word indicators of fake/real news. We have subjectively chosen **RandomForest** model and **Shapley values** for this purposes.\n\nNote: data preprocessing and model creation is work of @MateuszBiesiadowski\n\n### 1. Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport string\nimport re\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport shap\n\nimport nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-21T21:24:03.396942Z","iopub.execute_input":"2022-06-21T21:24:03.398041Z","iopub.status.idle":"2022-06-21T21:24:08.807439Z","shell.execute_reply.started":"2022-06-21T21:24:03.397923Z","shell.execute_reply":"2022-06-21T21:24:08.806019Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### 2. Data loading and preprocessing\nPlease note that test set is not explicitly stated, so we randomly choose our own and utilize it through further work.\n\nIn a nutshell, we decided to:\n* remove all non alphabetical characters and urls,\n* remove all english stopwords,\n* utilize stemming.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/fake-news-classification/WELFake_Dataset.csv', \n                   index_col=0)\ndata = data.dropna()\ny, X = data.loc[:, 'label'], data.loc[:, data.columns != 'label']","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:24:08.810427Z","iopub.execute_input":"2022-06-21T21:24:08.811536Z","iopub.status.idle":"2022-06-21T21:24:14.738453Z","shell.execute_reply.started":"2022-06-21T21:24:08.811485Z","shell.execute_reply":"2022-06-21T21:24:14.737023Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X_clean = pd.DataFrame({\"title_text\": X['title'] + \" \" + X['text']})","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:24:14.740392Z","iopub.execute_input":"2022-06-21T21:24:14.741097Z","iopub.status.idle":"2022-06-21T21:24:15.111240Z","shell.execute_reply.started":"2022-06-21T21:24:14.741050Z","shell.execute_reply":"2022-06-21T21:24:15.110012Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"stopwords = set(nltk.corpus.stopwords.words('english'))\nporter_steemer = nltk.stem.PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:24:15.113862Z","iopub.execute_input":"2022-06-21T21:24:15.114181Z","iopub.status.idle":"2022-06-21T21:24:15.124777Z","shell.execute_reply.started":"2022-06-21T21:24:15.114150Z","shell.execute_reply":"2022-06-21T21:24:15.123274Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def remove_urls(text):\n    URL_REGEX = r\"[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n    return re.sub(URL_REGEX, '', text)\n\ndef remove_non_alphabetical_characters(text):\n    return re.sub('[^a-zA-Z]', ' ', text)\n\ndef remove_stopwords(text):\n    words = text.split()\n    return ' '.join([word for word in words if word not in stopwords])\n    \ndef stem_words(text):\n    words = text.split()\n    return ' '.join([porter_steemer.stem(word) for word in words])\n\ndef transform_text(text):\n    text = remove_urls(text)\n    text = remove_non_alphabetical_characters(text)\n    text = text.lower()\n    text = remove_stopwords(text)\n    text = stem_words(text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:24:15.126707Z","iopub.execute_input":"2022-06-21T21:24:15.127051Z","iopub.status.idle":"2022-06-21T21:24:15.137113Z","shell.execute_reply.started":"2022-06-21T21:24:15.127019Z","shell.execute_reply":"2022-06-21T21:24:15.136111Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_clean['title_text'] = X_clean['title_text'].apply(transform_text)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:24:15.138759Z","iopub.execute_input":"2022-06-21T21:24:15.139612Z","iopub.status.idle":"2022-06-21T21:36:27.154140Z","shell.execute_reply.started":"2022-06-21T21:24:15.139578Z","shell.execute_reply":"2022-06-21T21:36:27.152792Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 3. Model creation","metadata":{}},{"cell_type":"code","source":"class SimpleModelEval:\n    def __init__(self, X, y, model, test_size=0.33, random_state=256):\n        self.X = X\n        self.y = y\n        self.model = model\n        self.test_size = test_size\n        self.random_state = random_state\n        self.results = dict()\n        self.eval_data = (None, None)\n    \n    def train_eval(self):\n        X_train, X_test, y_train, y_test = model_selection.train_test_split(\n            self.X, self.y, test_size=0.33, random_state=256, stratify=self.y)\n        self.eval_data = (X_test, y_test)\n        \n        self._train_eval_model(self.model, X_train, X_test, y_train, y_test)\n    \n    def _train_eval_model(self, model, X_train, X_test, y_train, y_test):\n        model_name = model.__class__.__name__\n        # Training model using training dataset\n        model.fit(X_train, y_train)\n        # Predicting the y variable for the testing dataset\n        y_pred = model.predict(X_test)\n\n        # Calculating accuracy score using predicted results and actual results\n        acc = accuracy_score(y_test, y_pred)\n        print(f\"{model_name} fake news detection with {100 * round(acc, 4)}% accuracy\")\n\n        # Calculating False Positive Rate\n        cf_matrix = confusion_matrix(y_test, y_pred)\n        tn, fp, fn, tp = cf_matrix.ravel()\n        fpr = fp / (fp + tn)\n        \n        # Calculating F1-score\n        f1 = f1_score(y_test, y_pred)\n        \n        # Saving results\n        self.results[model_name] = {\n            \"acc\": acc, \"fpr\": fpr, \"f1\": f1\n        }\n        \n        # The code below presents a confusion matrix\n        cf_matrix = confusion_matrix(y_test, y_pred)\n        ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n\n        ax.set_title(f'Confusion Matrix {model_name}\\n');\n        ax.set_xlabel('\\nPredicted Values')\n        ax.set_ylabel('Actual Values ');\n\n        ax.xaxis.set_ticklabels(['False','True'])\n        ax.yaxis.set_ticklabels(['False','True'])\n\n        plt.show()\n        \n    def get_results(self):\n        return pd.DataFrame.from_dict(self.results, orient='index')\n    \n    def get_model(self):\n        return self.model\n    \n    def get_eval_data(self):\n        return self.eval_data","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:36:27.155826Z","iopub.execute_input":"2022-06-21T21:36:27.156159Z","iopub.status.idle":"2022-06-21T21:36:27.171956Z","shell.execute_reply.started":"2022-06-21T21:36:27.156127Z","shell.execute_reply":"2022-06-21T21:36:27.170592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_model(max_features=1000, random_state=256):\n    cv = CountVectorizer(max_features=max_features)\n    X_bow = cv.fit_transform(\n        X_clean.title_text[~X_clean.title_text.isna()]\n    ).toarray()\n    y_tt = y[~X_clean.title_text.isna()]\n    \n    model = RandomForestClassifier(random_state=random_state, n_estimators=200)\n    sme = SimpleModelEval(X_bow, y_tt, model, random_state=random_state)\n    sme.train_eval()\n    \n    return sme.get_model(), sme.get_results(), sme.get_eval_data()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:36:27.173767Z","iopub.execute_input":"2022-06-21T21:36:27.174279Z","iopub.status.idle":"2022-06-21T21:36:27.187140Z","shell.execute_reply.started":"2022-06-21T21:36:27.174206Z","shell.execute_reply":"2022-06-21T21:36:27.185896Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model, results, (X_test, y_test) = train_model()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:36:27.189562Z","iopub.execute_input":"2022-06-21T21:36:27.190053Z","iopub.status.idle":"2022-06-21T21:37:49.146704Z","shell.execute_reply.started":"2022-06-21T21:36:27.189992Z","shell.execute_reply":"2022-06-21T21:37:49.145498Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:37:49.149684Z","iopub.execute_input":"2022-06-21T21:37:49.150009Z","iopub.status.idle":"2022-06-21T21:37:49.165318Z","shell.execute_reply.started":"2022-06-21T21:37:49.149968Z","shell.execute_reply":"2022-06-21T21:37:49.163806Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### 4. Explain some misclassified examples\n\nSince calculating Shapley values is computationally exhaustive, we have chosen 100 examples of correctly classified fake news from test data set, and created explanations solely based on them.","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:37:49.167150Z","iopub.execute_input":"2022-06-21T21:37:49.167909Z","iopub.status.idle":"2022-06-21T21:37:51.443536Z","shell.execute_reply.started":"2022-06-21T21:37:49.167859Z","shell.execute_reply":"2022-06-21T21:37:51.442159Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"fakes = np.random.choice(np.where((y_pred == 0) & (y_test == 0))[0], 100)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T22:50:49.173918Z","iopub.execute_input":"2022-06-21T22:50:49.174706Z","iopub.status.idle":"2022-06-21T22:50:49.181819Z","shell.execute_reply.started":"2022-06-21T22:50:49.174657Z","shell.execute_reply":"2022-06-21T22:50:49.180814Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"explainer = shap.Explainer(\n    lambda x: model.predict_proba(x)[:, 1],\n    X_test[fakes, :],\n    feature_names=cv.get_feature_names_out(),\n)\nshap_values = explainer(X_test[fakes, :], max_evals=1989)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T22:50:54.632678Z","iopub.execute_input":"2022-06-21T22:50:54.633430Z","iopub.status.idle":"2022-06-21T23:03:04.203115Z","shell.execute_reply.started":"2022-06-21T22:50:54.633382Z","shell.execute_reply":"2022-06-21T23:03:04.201685Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"shap.plots.beeswarm(shap_values, max_display=20)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T23:10:28.072313Z","iopub.execute_input":"2022-06-21T23:10:28.072731Z","iopub.status.idle":"2022-06-21T23:10:29.033362Z","shell.execute_reply.started":"2022-06-21T23:10:28.072693Z","shell.execute_reply":"2022-06-21T23:10:29.031803Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"Comments and spot-on observations:\n* as concluded during EDA, many occurences of \"video\" are indicators of news' authenticity,\n* similarily, \"Breitbart\" is more common for fake news as well as \"Reuter\" is obviously common for real news,\n* \"said\" is a very interesting example; maybe fake news are avoiding giving specifics, so it is harder to verify informations?\n* for some reason \"via\" makes news more trustworthy, but it could be a bias coming from small sample (only 100 examples).","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    shap.plots.waterfall(shap_values[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T23:14:50.009755Z","iopub.execute_input":"2022-06-21T23:14:50.010700Z","iopub.status.idle":"2022-06-21T23:14:59.687459Z","shell.execute_reply.started":"2022-06-21T23:14:50.010653Z","shell.execute_reply":"2022-06-21T23:14:59.685683Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}