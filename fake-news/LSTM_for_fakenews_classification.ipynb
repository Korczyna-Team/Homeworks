{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_for_fakenews_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TX9u3oDtAXBp"
      },
      "outputs": [],
      "source": [
        "!pip install clearml > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "dDbjxVAjAg4E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/df_title.csv', names=['id', 'title', 'class'], header=None, skiprows=1)"
      ],
      "metadata": {
        "id": "0gYv0eW3CsYd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns='id', inplace=True)"
      ],
      "metadata": {
        "id": "uKyacueZIBjt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean_title = df"
      ],
      "metadata": {
        "id": "tcFyzQzXAyL8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean_title.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9FIu2piqKJK2",
        "outputId": "eb6b0bc3-f197-4370-f041-52cadccfae5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  class\n",
              "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...    1.0\n",
              "1  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...    1.0\n",
              "2  Bobby Jindal, raised Hindu, uses story of Chri...    0.0\n",
              "3  SATAN 2: Russia unvelis an image of its terrif...    1.0\n",
              "4  About Time! Christian Group Sues Amazon and SP...    1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e17f0c3-651a-442b-9e11-80aa9acf0b48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e17f0c3-651a-442b-9e11-80aa9acf0b48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e17f0c3-651a-442b-9e11-80aa9acf0b48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e17f0c3-651a-442b-9e11-80aa9acf0b48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3pdciImKP8M",
        "outputId": "224b8d2d-01f6-49e9-c836-4a0eec357d46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "porter_steemer = nltk.stem.PorterStemmer()"
      ],
      "metadata": {
        "id": "Jy9QaF9zA5Vj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "    URL_REGEX = r\"[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
        "    return re.sub(URL_REGEX, '', text)\n",
        "\n",
        "def remove_non_alphabetical_characters(text):\n",
        "    return re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([word for word in words if word not in stopwords])\n",
        "    \n",
        "def stem_words(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([porter_steemer.stem(word) for word in words])\n",
        "  \n",
        "def transform_text(text):\n",
        "    text = remove_urls(text)\n",
        "    text = remove_non_alphabetical_characters(text)\n",
        "    text = text.lower()\n",
        "    text = remove_stopwords(text)\n",
        "    text = stem_words(text)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "MCGUC0FkA6AV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean_title['title'] = X_clean_title['title'].apply(transform_text)"
      ],
      "metadata": {
        "id": "fectk29vBBOR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean_title = X_clean_title[X_clean_title['title'].str.len() > 0]"
      ],
      "metadata": {
        "id": "yZHevklkBYjd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean_title.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtioJl49Ko2-",
        "outputId": "ce43fd1f-2d65-46cf-8950-b0896cd33677"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "            X_clean_title['title'], X_clean_title['class'], test_size=0.33, random_state=256, stratify=X_clean_title['class'])"
      ],
      "metadata": {
        "id": "aElM4PRvBZsx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = []\n",
        "for index, row in X_clean_title.iterrows():\n",
        "    if index in X_train.index:\n",
        "        split.append('train')\n",
        "    else:\n",
        "        split.append('test')\n",
        "X_clean_title['split'] = split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-6MG7zEBcBk",
        "outputId": "b8ac3e43-ce00-47f6-f331-94e611808d6a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PADDING_VALUE = 0\n",
        "\n",
        "class NaiveVectorizer:\n",
        "    def __init__(self, tokenized_data, **kwargs):\n",
        "        tokenized_data = [seq.split() for seq in tokenized_data]\n",
        "        self.wv = dict()\n",
        "        iter = PADDING_VALUE + 1\n",
        "        for sequence in tokenized_data:\n",
        "          for word in sequence:\n",
        "            if word not in self.wv:\n",
        "              self.wv[word] = iter\n",
        "              iter += 1\n",
        "\n",
        "    def vectorize(self, tokenized_seq):\n",
        "        tokens = []\n",
        "        for word in tokenized_seq:\n",
        "          if word in self.wv:\n",
        "            tokens.append(self.wv[word])\n",
        "            \n",
        "        return torch.LongTensor(tokens)"
      ],
      "metadata": {
        "id": "UtVzJGRjBd9Q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetNews(Dataset):\n",
        "    SPLIT_TYPES = [\"train\", \"test\"]\n",
        "\n",
        "    def __init__(self, data, preprocess_fn, split=\"train\"):\n",
        "        super(DatasetNews, self).__init__()\n",
        "        if split not in self.SPLIT_TYPES:\n",
        "            raise AttributeError(f\"No such split type: {split}\")\n",
        "\n",
        "        self.split = split\n",
        "        self.label = [i for i, c in enumerate(data.columns) if c == \"class\"][0]\n",
        "        self.data_col = [i for i, c in enumerate(data.columns) if c == \"title\"][0]\n",
        "        self.data = data[data[\"split\"] == self.split]\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.preprocess_fn(self.data.iloc[idx, self.data_col].split())\n",
        "        label = self.data.iloc[idx, self.label]\n",
        "        return (seq, label)"
      ],
      "metadata": {
        "id": "XlZhTDmFBvcU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "naive_vectorizer = NaiveVectorizer(X_clean_title.loc[X_clean_title[\"split\"] == \"train\", \"title\"])\n",
        "\n",
        "def get_datasets():\n",
        "    train_dataset = DatasetNews(data=X_clean_title, preprocess_fn=naive_vectorizer.vectorize)\n",
        "    test_dataset = DatasetNews(data=X_clean_title, preprocess_fn=naive_vectorizer.vectorize, split=\"test\")\n",
        "        \n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def custom_collate_fn(pairs):\n",
        "    seqcs, lengths, labels = [], [], []\n",
        "    for pair in pairs:\n",
        "        if len(pair[0]) > 0:\n",
        "          labels.append(pair[1])\n",
        "          lengths.append(len(pair[0]))\n",
        "          seqcs.append(pair[0])\n",
        "\n",
        "    seqcs = pad_sequence(seqcs, padding_value=PADDING_VALUE)\n",
        "    lengths = torch.LongTensor(lengths)\n",
        "    labels = torch.Tensor(labels)\n",
        "    return seqcs, lengths, labels"
      ],
      "metadata": {
        "id": "JV0ZFevhB0Xf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, classes, batch_size, dropout_prob, num_layers):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers =num_layers, dropout=dropout_prob)\n",
        "        self.linear = nn.Linear(hidden_dim, classes)\n",
        "        self.drop = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, sentence, lengths):\n",
        "        batch_size = sentence.shape[1]\n",
        "        embeddings = self.embedding(sentence)\n",
        "        embeddings = self.drop(embeddings)\n",
        "        packed_embeddings = pack_padded_sequence(embeddings, lengths.cpu(), enforce_sorted=False)\n",
        "        lstm_out, _ = self.lstm(packed_embeddings)\n",
        "        output, hidden = pad_packed_sequence(lstm_out)\n",
        "        out = output[lengths - 1, range(batch_size) , :]\n",
        "        x = self.linear(out)\n",
        "        x = x.squeeze()\n",
        "        scores = torch.sigmoid(x)\n",
        "        return scores"
      ],
      "metadata": {
        "id": "K4ItYInHB7T6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from clearml import Task"
      ],
      "metadata": {
        "id": "e7HsxwzeK3V_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_server = 'https://app.community.clear.ml'\n",
        "api_server = 'https://api.community.clear.ml'\n",
        "files_server = 'https://files.community.clear.ml'\n",
        "access_key = \"\"\n",
        "secret_key = \"\"\n",
        "\n",
        "Task.set_credentials(web_host=web_server,\n",
        "                     api_host=api_server,\n",
        "                     files_host=files_server,\n",
        "                     key=access_key,\n",
        "                     secret=secret_key)"
      ],
      "metadata": {
        "id": "D9TfpcgrK90O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task.create(project_name='cloud', task_name='log1')\n",
        "task.mark_started()\n",
        "logger = task.get_logger()"
      ],
      "metadata": {
        "id": "9FxK5-xoB-w1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'n_epochs': 20,\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 128, \n",
        "    'optimizer': 'Adam',\n",
        "    'hidden_dim': 128, \n",
        "    'embedding_dim': 50,\n",
        "    'dropout': 0.5, \n",
        "    'num_layers': 2\n",
        "}\n",
        "task.connect(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7nVOuVgCCF6",
        "outputId": "b5fcb084-0cf6-4e2c-d6d8-eb7e78e3a493"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'dropout': 0.5,\n",
              " 'embedding_dim': 50,\n",
              " 'hidden_dim': 128,\n",
              " 'lr': 0.001,\n",
              " 'n_epochs': 20,\n",
              " 'num_layers': 2,\n",
              " 'optimizer': 'Adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, training_data, test_data, optimizer, device, loss_fn):\n",
        "\n",
        "    for epoch in range(config['n_epochs']):\n",
        "\n",
        "        print('[ Epoch', epoch, ']')\n",
        "        \n",
        "        start = time.time()\n",
        "        train_loss, train_acc, train_f1, train_fpr = train_epoch(model, training_data, optimizer, device, loss_fn)\n",
        "        print('  - (Training)   loss: {loss: 8.5f}, accuracy: {acc:3.3f} %, f1: {f1:3.3f}%, fpr: {fpr:3.3f}%, time: {time:3.3f} min'.format(\n",
        "            loss = train_loss, acc=100*train_acc, f1=100*train_f1, fpr=100*train_fpr,\n",
        "            time=(time.time()-start)/60))\n",
        "        \n",
        "        start = time.time()\n",
        "        test_loss, test_acc, test_f1, test_fpr = eval_epoch(model, test_data, device, loss_fn)\n",
        "        print('  - (Test)       loss: {loss: 8.5f}, accuracy: {acc:3.3f} %, f1: {f1:3.3f}%, fpr: {fpr:3.3f}%, time: {time:3.3f} min'.format(\n",
        "            loss = test_loss, acc=100*test_acc, f1=100*test_f1, fpr=100*test_fpr,\n",
        "            time=(time.time()-start)/60))\n",
        "\n",
        "        logger.report_scalar(title='Loss', series='Train', iteration=epoch, value=train_loss)\n",
        "        logger.report_scalar(title='Accuracy', series='Train', iteration=epoch, value=train_acc)\n",
        "        logger.report_scalar(title='Loss', series='Test', iteration=epoch, value=test_loss)\n",
        "        logger.report_scalar(title='Accuracy', series='Test', iteration=epoch, value=test_acc)\n",
        "        logger.report_scalar(title='F1', series='Test', iteration=epoch, value=test_f1)\n",
        "        logger.report_scalar(title='FPR', series='Test', iteration=epoch, value=test_fpr)\n",
        "        logger.report_scalar(title='F1', series='Train', iteration=epoch, value=train_f1)\n",
        "        logger.report_scalar(title='FPR', series='Train', iteration=epoch, value=train_fpr)"
      ],
      "metadata": {
        "id": "g0rq3W4QCEcH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, training_data, optimizer, device, loss_fn):\n",
        "    \n",
        "        model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "        n_examples_total, n_examples_correct = 0, 0\n",
        "\n",
        "        for batch in tqdm(training_data, mininterval=2,desc='  - (Training)   ', leave=False):\n",
        "\n",
        "            seqcs, lengths, labels = batch[0].to(device), batch[1], batch[2].to(device)\n",
        "            # forward\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(seqcs, lengths)\n",
        "\n",
        "            # backward\n",
        "            loss, n_correct = eval_performance(pred, labels, loss_fn)\n",
        "            loss.backward()\n",
        "            # Calculating False Positive Rate\n",
        "            cf_matrix = confusion_matrix(labels.detach().cpu().numpy(), torch.round(pred).detach().cpu().numpy())\n",
        "            tn, fp, fn, tp = cf_matrix.ravel()\n",
        "            fpr = fp / (fp + tn)\n",
        "\n",
        "            # Calculating F1-score\n",
        "            f1 = f1_score(labels.detach().cpu().numpy(), torch.round(pred).detach().cpu().numpy())\n",
        "\n",
        "            # update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            n_examples_total += batch[2].size()[0]\n",
        "            n_examples_correct += n_correct\n",
        "            # print(f'Loss: {loss.item()}, acc: {n_correct/batch[2].size()[0]}')\n",
        "\n",
        "        accuracy = n_examples_correct/n_examples_total\n",
        "\n",
        "        return total_loss, accuracy, f1, fpr"
      ],
      "metadata": {
        "id": "2vnqWrj-CJer"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(model, test_data, device, loss_fn):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    n_examples_total, n_examples_correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_data, mininterval=2, desc='  - (Test) ', leave=False):\n",
        "\n",
        "            seqcs, lengths, labels = batch[0].to(device), batch[1], batch[2].to(device)\n",
        "            \n",
        "            # forward\n",
        "            pred = model(seqcs, lengths)\n",
        "            loss, n_correct = eval_performance(pred, labels, loss_fn)\n",
        "            # Calculating False Positive Rate\n",
        "            cf_matrix = confusion_matrix(labels.detach().cpu().numpy(), torch.round(pred).detach().cpu().numpy())\n",
        "            tn, fp, fn, tp = cf_matrix.ravel()\n",
        "            fpr = fp / (fp + tn)\n",
        "\n",
        "            # Calculating F1-score\n",
        "            f1 = f1_score(labels.detach().cpu().numpy(), torch.round(pred).detach().cpu().numpy())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            n_examples_total += batch[2].size()[0]\n",
        "            n_examples_correct += n_correct\n",
        "\n",
        "    accuracy = n_examples_correct/n_examples_total\n",
        "\n",
        "    return total_loss, accuracy, f1, fpr"
      ],
      "metadata": {
        "id": "vobOAi0fCR4f"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_performance(prediction, ground_truth, loss_fn):\n",
        "    \n",
        "    loss = loss_fn(prediction, ground_truth)\n",
        "\n",
        "    n_correct = (torch.round(prediction) == ground_truth.to(torch.int32)).sum().item()\n",
        "\n",
        "    return loss, n_correct"
      ],
      "metadata": {
        "id": "M_xWupHtCU6v"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, test_data = get_datasets()\n",
        "train_dataloader = DataLoader(training_data, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_collate_fn)\n",
        "test_dataloader = DataLoader(test_data, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_collate_fn)"
      ],
      "metadata": {
        "id": "66hRHXpRCXWC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LSTMClassifier(embedding_dim=config['embedding_dim'], hidden_dim=config['hidden_dim'], vocab_size=len(naive_vectorizer.wv)+1, classes=1, batch_size=config['batch_size'], dropout_prob=config['dropout'], num_layers=config['num_layers']).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "loss = nn.BCELoss()\n",
        "train(model=model, training_data=train_dataloader, test_data=test_dataloader, optimizer=optimizer, device=DEVICE, loss_fn=loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCpDmlOpCZ6W",
        "outputId": "9335675e-07c1-4e1a-bb48-1cd99263447b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Epoch 0 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  149.65548, accuracy: 73.737 %, f1: 76.190%, fpr: 15.789%, time: 0.092 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  55.13934, accuracy: 83.166 %, f1: 85.714%, fpr: 12.500%, time: 0.032 min\n",
            "[ Epoch 1 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  116.02960, accuracy: 81.917 %, f1: 87.805%, fpr: 13.636%, time: 0.092 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  48.76224, accuracy: 85.326 %, f1: 88.462%, fpr: 23.810%, time: 0.032 min\n",
            "[ Epoch 2 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  104.95052, accuracy: 84.597 %, f1: 70.270%, fpr: 21.739%, time: 0.092 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  44.66654, accuracy: 87.385 %, f1: 90.000%, fpr: 8.000%, time: 0.032 min\n",
            "[ Epoch 3 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  98.09499, accuracy: 85.839 %, f1: 87.179%, fpr: 9.091%, time: 0.120 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  42.99650, accuracy: 87.966 %, f1: 93.548%, fpr: 20.000%, time: 0.032 min\n",
            "[ Epoch 4 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  92.00742, accuracy: 86.908 %, f1: 91.667%, fpr: 11.111%, time: 0.092 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  41.60111, accuracy: 88.302 %, f1: 100.000%, fpr: 0.000%, time: 0.032 min\n",
            "[ Epoch 5 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  88.31726, accuracy: 87.506 %, f1: 88.372%, fpr: 18.182%, time: 0.139 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  39.61680, accuracy: 89.025 %, f1: 86.667%, fpr: 9.677%, time: 0.035 min\n",
            "[ Epoch 6 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  84.41592, accuracy: 88.211 %, f1: 96.296%, fpr: 0.000%, time: 0.093 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  39.89922, accuracy: 88.908 %, f1: 94.545%, fpr: 11.111%, time: 0.050 min\n",
            "[ Epoch 7 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  81.15137, accuracy: 88.821 %, f1: 91.304%, fpr: 15.000%, time: 0.122 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  38.07328, accuracy: 89.586 %, f1: 91.667%, fpr: 13.636%, time: 0.032 min\n",
            "[ Epoch 8 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  77.96278, accuracy: 89.350 %, f1: 90.909%, fpr: 10.000%, time: 0.092 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  39.14331, accuracy: 89.356 %, f1: 93.878%, fpr: 0.000%, time: 0.032 min\n",
            "[ Epoch 9 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  75.71261, accuracy: 89.696 %, f1: 82.353%, fpr: 25.000%, time: 0.093 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  37.74104, accuracy: 89.728 %, f1: 92.683%, fpr: 8.000%, time: 0.032 min\n",
            "[ Epoch 10 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  73.10457, accuracy: 90.241 %, f1: 93.333%, fpr: 10.000%, time: 0.118 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  37.96866, accuracy: 89.988 %, f1: 89.796%, fpr: 10.000%, time: 0.033 min\n",
            "[ Epoch 11 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  70.63579, accuracy: 90.600 %, f1: 93.333%, fpr: 5.263%, time: 0.098 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  37.45251, accuracy: 90.218 %, f1: 97.297%, fpr: 3.704%, time: 0.033 min\n",
            "[ Epoch 12 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  68.72892, accuracy: 90.748 %, f1: 91.304%, fpr: 19.048%, time: 0.095 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  36.98653, accuracy: 90.401 %, f1: 93.617%, fpr: 13.043%, time: 0.032 min\n",
            "[ Epoch 13 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  67.32765, accuracy: 90.934 %, f1: 75.000%, fpr: 15.000%, time: 0.095 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  36.29257, accuracy: 90.386 %, f1: 83.333%, fpr: 14.286%, time: 0.032 min\n",
            "[ Epoch 14 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  65.95870, accuracy: 91.315 %, f1: 85.714%, fpr: 12.000%, time: 0.094 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  37.60416, accuracy: 90.105 %, f1: 97.959%, fpr: 4.762%, time: 0.032 min\n",
            "[ Epoch 15 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  62.98937, accuracy: 91.614 %, f1: 92.308%, fpr: 3.448%, time: 0.095 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  38.54480, accuracy: 90.416 %, f1: 86.486%, fpr: 4.000%, time: 0.032 min\n",
            "[ Epoch 16 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  61.65721, accuracy: 91.890 %, f1: 86.667%, fpr: 7.407%, time: 0.095 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  34.89068, accuracy: 90.819 %, f1: 88.372%, fpr: 12.500%, time: 0.032 min\n",
            "[ Epoch 17 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  61.55452, accuracy: 91.867 %, f1: 90.909%, fpr: 18.182%, time: 0.093 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  36.18091, accuracy: 90.763 %, f1: 90.196%, fpr: 10.526%, time: 0.033 min\n",
            "[ Epoch 18 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  59.23915, accuracy: 92.100 %, f1: 85.000%, fpr: 17.391%, time: 0.103 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  37.46159, accuracy: 90.747 %, f1: 86.275%, fpr: 23.810%, time: 0.032 min\n",
            "[ Epoch 19 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Training)   loss:  58.03652, accuracy: 92.429 %, f1: 93.333%, fpr: 14.286%, time: 0.093 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - (Test)       loss:  38.17297, accuracy: 90.442 %, f1: 95.833%, fpr: 0.000%, time: 0.033 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task.mark_completed()\n",
        "task.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRFUCJ6eLyDN",
        "outputId": "c1a4237e-9cf7-4871-e307-b99dc918fb7a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-21 21:35:38,994 - clearml.Task - INFO - Waiting to finish uploads\n",
            "2022-06-21 21:35:39,100 - clearml.Task - INFO - Finished uploading\n"
          ]
        }
      ]
    }
  ]
}